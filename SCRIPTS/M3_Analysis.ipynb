{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "56Wt86mMPQ-I"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "base_path = '/content/drive/MyDrive/DS Project 3'\n",
        "train_path = os.path.join(base_path, 'training_images')\n",
        "test_path = os.path.join(base_path, 'test_images')\n",
        "\n",
        "print(f\"Training path: {train_path}\")\n",
        "print(f\"Testing path: {test_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbEqRus5QM0c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "# Parameters\n",
        "image_size = (125, 125)  # Updated size compatible with MobileNetV2\n",
        "batch_size = 32\n",
        "\n",
        "def load_images_and_labels(folder_path):\n",
        "    filenames = []\n",
        "    labels = []\n",
        "    groups = []\n",
        "\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.lower().endswith('.jpg'):  # Only process .jpg files\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            try:\n",
        "                # Extract the phase (class label) from the filename\n",
        "                label = int(file.split('_')[-1].split('.')[0])  # Last number before \".jpg\"\n",
        "                if 1 <= label <= 5:  # Validate label is within bounds\n",
        "                    filenames.append(file_path)\n",
        "                    labels.append(label - 1)  # Adjust labels to range [0, 4]\n",
        "\n",
        "                    # Group by prefix (e.g., \"Tam_d07\")\n",
        "                    group = \"_\".join(file.split('_')[:2])\n",
        "                    groups.append(group)\n",
        "                else:\n",
        "                    print(f\"Skipping file with invalid label: {file}\")\n",
        "            except ValueError:\n",
        "                print(f\"Skipping file due to label extraction issue: {file}\")\n",
        "\n",
        "    print(f\"Loaded {len(filenames)} images and labels from {folder_path}\")\n",
        "    return filenames, labels, groups\n",
        "\n",
        "# Load training and testing datasets\n",
        "print(\"Loading training dataset...\")\n",
        "train_filenames, train_labels, train_groups = load_images_and_labels(train_path)\n",
        "\n",
        "print(\"Loading testing dataset...\")\n",
        "test_filenames, test_labels, _ = load_images_and_labels(test_path)\n",
        "\n",
        "def preprocess_image(file_path, label):\n",
        "    # Load and preprocess the image\n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, image_size) / 255.0  # Normalize pixel values\n",
        "    return image, label\n",
        "\n",
        "def create_dataset(filenames, labels, batch_size):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
        "    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDWVPBMuQOjt"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "fold_results = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(gkf.split(train_filenames, train_labels, train_groups)):\n",
        "    print(f\"Processing Fold {fold + 1}...\")\n",
        "\n",
        "    # Split training and validation sets for this fold\n",
        "    train_files = [train_filenames[i] for i in train_idx]\n",
        "    train_fold_labels = [train_labels[i] for i in train_idx]\n",
        "    val_files = [train_filenames[i] for i in val_idx]\n",
        "    val_fold_labels = [train_labels[i] for i in val_idx]\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = create_dataset(train_files, train_fold_labels, batch_size)\n",
        "    val_dataset = create_dataset(val_files, val_fold_labels, batch_size)\n",
        "\n",
        "    # Build MobileNetV2 model\n",
        "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Dropout(0.3)(x)\n",
        "    predictions = Dense(5, activation='softmax')(x)  # Assuming 5 ripeness stages\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    # Freeze base layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=3,  # Reduced epochs for faster cross-validation\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_loss, val_accuracy = model.evaluate(val_dataset, verbose=1)\n",
        "    fold_results.append(val_accuracy)\n",
        "\n",
        "print(f\"Cross-validation accuracies: {fold_results}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zykYY7cLbwou"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "# Prepare the test dataset\n",
        "test_dataset = create_dataset(test_filenames, test_labels, batch_size)\n",
        "\n",
        "# Evaluate the model on the testing dataset\n",
        "print(\"Evaluating the model on the testing dataset...\")\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset, verbose=1)\n",
        "\n",
        "# Generate predictions\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "for images, labels in test_dataset:\n",
        "    preds = tf.argmax(model.predict(images), axis=1).numpy()\n",
        "    predictions.extend(preds)\n",
        "    true_labels.extend(labels.numpy())\n",
        "\n",
        "# Metrics for testing set\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels, predictions))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(true_labels, predictions))\n",
        "\n",
        "# One-sample t-test to compare cross-validation accuracies to random guessing (20% for 5 classes)\n",
        "random_guess_accuracy = 0.2\n",
        "t_stat, p_value = ttest_1samp(fold_results, random_guess_accuracy)\n",
        "print(f\"T-Test Results: t-stat={t_stat:.4f}, p-value={p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"The model's performance is significantly better than random guessing.\")\n",
        "else:\n",
        "    print(\"The model's performance is NOT significantly better than random guessing.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}